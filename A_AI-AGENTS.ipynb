{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3f01150-7def-4888-ad64-289f13279519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: livekit-agents in /home/daniel/anaconda3/lib/python3.12/site-packages (1.2.11)\n",
      "Requirement already satisfied: exa-py in /home/daniel/anaconda3/lib/python3.12/site-packages (1.15.6)\n",
      "Requirement already satisfied: cerebras-cloud-sdk in /home/daniel/anaconda3/lib/python3.12/site-packages (1.50.1)\n",
      "Requirement already satisfied: langchain in /home/daniel/anaconda3/lib/python3.12/site-packages (0.1.13)\n",
      "Requirement already satisfied: langgraph in /home/daniel/anaconda3/lib/python3.12/site-packages (0.0.51)\n",
      "Requirement already satisfied: aiohttp~=3.10 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (3.10.5)\n",
      "Requirement already satisfied: av>=14.0.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (15.1.0)\n",
      "Requirement already satisfied: click~=8.1 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (8.1.7)\n",
      "Requirement already satisfied: colorama>=0.4.6 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (0.4.6)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (0.17.0)\n",
      "Requirement already satisfied: eval-type-backport in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (0.2.2)\n",
      "Requirement already satisfied: livekit-api<2,>=1.0.5 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (1.0.5)\n",
      "Requirement already satisfied: livekit-blingfire~=1.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (1.0.0)\n",
      "Requirement already satisfied: livekit-protocol~=1.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (1.0.6)\n",
      "Requirement already satisfied: livekit<2,>=1.0.12 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (1.0.13)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.99.2 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (1.108.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.34 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp>=1.34.1 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.34.1 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (1.37.0)\n",
      "Requirement already satisfied: prometheus-client>=0.22 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (0.23.1)\n",
      "Requirement already satisfied: protobuf>=3 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (6.32.1)\n",
      "Requirement already satisfied: psutil>=7.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (7.1.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (2.11.9)\n",
      "Requirement already satisfied: pyjwt>=2.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (2.8.0)\n",
      "Requirement already satisfied: sounddevice>=0.5 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (0.5.2)\n",
      "Requirement already satisfied: types-protobuf>=4 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (6.32.1.20250918)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (4.14.1)\n",
      "Requirement already satisfied: watchfiles>=1.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit-agents) (1.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from aiohttp~=3.10->livekit-agents) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/daniel/anaconda3/lib/python3.12/site-packages (from aiohttp~=3.10->livekit-agents) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from aiohttp~=3.10->livekit-agents) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/daniel/anaconda3/lib/python3.12/site-packages (from aiohttp~=3.10->livekit-agents) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/daniel/anaconda3/lib/python3.12/site-packages (from aiohttp~=3.10->livekit-agents) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from aiohttp~=3.10->livekit-agents) (1.11.0)\n",
      "Requirement already satisfied: aiofiles>=24 in /home/daniel/anaconda3/lib/python3.12/site-packages (from livekit<2,>=1.0.12->livekit-agents) (24.1.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=2.0->livekit-agents) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/daniel/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=2.0->livekit-agents) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from pydantic<3,>=2.0->livekit-agents) (0.4.1)\n",
      "Requirement already satisfied: idna>=2.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from yarl<2.0,>=1.0->aiohttp~=3.10->livekit-agents) (3.7)\n",
      "Requirement already satisfied: httpx>=0.28.1 in /home/daniel/anaconda3/lib/python3.12/site-packages (from exa-py) (0.28.1)\n",
      "Requirement already satisfied: requests>=2.32.3 in /home/daniel/anaconda3/lib/python3.12/site-packages (from exa-py) (2.32.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from cerebras-cloud-sdk) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from cerebras-cloud-sdk) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /home/daniel/anaconda3/lib/python3.12/site-packages (from cerebras-cloud-sdk) (1.3.0)\n",
      "Requirement already satisfied: certifi in /home/daniel/anaconda3/lib/python3.12/site-packages (from httpx>=0.28.1->exa-py) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /home/daniel/anaconda3/lib/python3.12/site-packages (from httpx>=0.28.1->exa-py) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/daniel/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.28.1->exa-py) (0.14.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/daniel/anaconda3/lib/python3.12/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/daniel/anaconda3/lib/python3.12/site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/daniel/anaconda3/lib/python3.12/site-packages (from langchain) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/daniel/anaconda3/lib/python3.12/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.29 in /home/daniel/anaconda3/lib/python3.12/site-packages (from langchain) (0.0.29)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /home/daniel/anaconda3/lib/python3.12/site-packages (from langchain) (0.1.53)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /home/daniel/anaconda3/lib/python3.12/site-packages (from langchain) (0.0.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/daniel/anaconda3/lib/python3.12/site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/daniel/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/daniel/anaconda3/lib/python3.12/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/daniel/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/daniel/anaconda3/lib/python3.12/site-packages (from requests>=2.32.3->exa-py) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/daniel/anaconda3/lib/python3.12/site-packages (from requests>=2.32.3->exa-py) (2.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/daniel/anaconda3/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: uuid6<2025.0.0,>=2024.1.12 in /home/daniel/anaconda3/lib/python3.12/site-packages (from langgraph) (2024.7.10)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from openai>=1.99.2->livekit-agents) (0.11.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/daniel/anaconda3/lib/python3.12/site-packages (from openai>=1.99.2->livekit-agents) (4.66.5)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from opentelemetry-api>=1.34->livekit-agents) (6.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/daniel/anaconda3/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.34->livekit-agents) (3.17.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.37.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from opentelemetry-exporter-otlp>=1.34.1->livekit-agents) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.37.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from opentelemetry-exporter-otlp>=1.34.1->livekit-agents) (1.37.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /home/daniel/anaconda3/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.37.0->opentelemetry-exporter-otlp>=1.34.1->livekit-agents) (1.69.2)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.63.2 in /home/daniel/anaconda3/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.37.0->opentelemetry-exporter-otlp>=1.34.1->livekit-agents) (1.75.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.37.0->opentelemetry-exporter-otlp>=1.34.1->livekit-agents) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.37.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.37.0->opentelemetry-exporter-otlp>=1.34.1->livekit-agents) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from opentelemetry-sdk>=1.34.1->livekit-agents) (0.58b0)\n",
      "Requirement already satisfied: CFFI>=1.0 in /home/daniel/anaconda3/lib/python3.12/site-packages (from sounddevice>=0.5->livekit-agents) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/daniel/anaconda3/lib/python3.12/site-packages (from CFFI>=1.0->sounddevice>=0.5->livekit-agents) (2.21)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install livekit-agents exa-py cerebras-cloud-sdk langchain langgraph\n",
    "\n",
    "# Set environment variables\n",
    "# export CEREBRAS_API_KEY=\"your_cerebras_key\"\n",
    "# export LIVEKIT_API_KEY=\"your_livekit_key\" \n",
    "# export CARTESIA_API_KEY=\"your_cartesia_key\"\n",
    "# export EXA_API_KEY=\"your_exa_key\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd388d-287a-440b-88e8-cdbcc80db80f",
   "metadata": {},
   "source": [
    "1. Voice Sales Agent with LiveKit and Cartesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78096a5e-9faf-47f4-8b7d-9ace13464e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6315f587-0cfa-4d46-acd8-454c0d2735d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LLM' from 'livekit.agents' (/home/daniel/anaconda3/lib/python3.12/site-packages/livekit/agents/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Optional\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataclass\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlivekit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     Agent, \n\u001b[1;32m      7\u001b[0m     LLM, \n\u001b[1;32m      8\u001b[0m     STT, \n\u001b[1;32m      9\u001b[0m     TTS, \n\u001b[1;32m     10\u001b[0m     VoiceActivityDetector,\n\u001b[1;32m     11\u001b[0m     JobContext,\n\u001b[1;32m     12\u001b[0m     llm\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlivekit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VoicePipeline\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Step 1: Configuration and API Keys\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'LLM' from 'livekit.agents' (/home/daniel/anaconda3/lib/python3.12/site-packages/livekit/agents/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from typing import Dict, List, Optional\n",
    "from dataclasses import dataclass\n",
    "from livekit.agents import (\n",
    "    Agent, \n",
    "    LLM, \n",
    "    STT, \n",
    "    TTS, \n",
    "    VoiceActivityDetector,\n",
    "    JobContext,\n",
    "    llm\n",
    ")\n",
    "from livekit.agents.pipeline import VoicePipeline\n",
    "\n",
    "# Step 1: Configuration and API Keys\n",
    "@dataclass\n",
    "class AgentConfig:\n",
    "    cerebras_api_key: str\n",
    "    livekit_api_key: str\n",
    "    cartesia_api_key: str\n",
    "    llm_model: str = \"llama-3-70b\"\n",
    "    stt_model: str = \"cartesia-whisper-v3\"\n",
    "    tts_model: str = \"cartesia-sonic\"\n",
    "\n",
    "class SalesContext:\n",
    "    def __init__(self):\n",
    "        self.product_info = {}\n",
    "        self.pricing_data = {}\n",
    "        self.objection_handlers = {}\n",
    "        self.benefits = []\n",
    "    \n",
    "    def load_context(self, context_data: Dict):\n",
    "        \"\"\"Load sales context for the agent\"\"\"\n",
    "        self.product_info = context_data.get(\"product_description\", {})\n",
    "        self.pricing_data = context_data.get(\"pricing\", {})\n",
    "        self.objection_handlers = context_data.get(\"objection_handlers\", {})\n",
    "        self.benefits = context_data.get(\"key_benefits\", [])\n",
    "    \n",
    "    def get_context_prompt(self) -> str:\n",
    "        \"\"\"Create context prompt for the LLM\"\"\"\n",
    "        context_parts = []\n",
    "        \n",
    "        if self.product_info:\n",
    "            context_parts.append(f\"Product: {self.product_info.get('name', '')}\")\n",
    "            context_parts.append(f\"Description: {self.product_info.get('description', '')}\")\n",
    "        \n",
    "        if self.benefits:\n",
    "            context_parts.append(\"Key Benefits:\")\n",
    "            for benefit in self.benefits:\n",
    "                context_parts.append(f\"- {benefit}\")\n",
    "        \n",
    "        if self.pricing_data:\n",
    "            context_parts.append(\"Pricing:\")\n",
    "            for tier, price in self.pricing_data.items():\n",
    "                context_parts.append(f\"- {tier}: {price}\")\n",
    "        \n",
    "        if self.objection_handlers:\n",
    "            context_parts.append(\"Common Objection Responses:\")\n",
    "            for objection, response in self.objection_handlers.items():\n",
    "                context_parts.append(f\"Objection: '{objection}'\")\n",
    "                context_parts.append(f\"Response: '{response}'\")\n",
    "        \n",
    "        return \"\\n\".join(context_parts)\n",
    "\n",
    "class SalesAgent(Agent):\n",
    "    def __init__(self, config: AgentConfig, context: SalesContext):\n",
    "        self.config = config\n",
    "        self.context = context\n",
    "        \n",
    "        # Initialize AI components\n",
    "        self.llm = self._setup_llm()\n",
    "        self.stt = self._setup_stt()\n",
    "        self.tts = self._setup_tts()\n",
    "        self.vad = self._setup_vad()\n",
    "        \n",
    "        # Sales-specific instructions\n",
    "        self.instructions = self._create_instructions()\n",
    "        \n",
    "        super().__init__(\n",
    "            llm=self.llm,\n",
    "            stt=self.stt,\n",
    "            tts=self.tts,\n",
    "            vad=self.vad,\n",
    "            instructions=self.instructions\n",
    "        )\n",
    "    \n",
    "    def _setup_llm(self) -> LLM:\n",
    "        \"\"\"Configure Cerebras LLM\"\"\"\n",
    "        return LLM.create(\n",
    "            provider=\"cerebras\",\n",
    "            model=self.config.llm_model,\n",
    "            api_key=self.config.cerebras_api_key\n",
    "        )\n",
    "    \n",
    "    def _setup_stt(self) -> STT:\n",
    "        \"\"\"Configure Cartesia Speech-to-Text\"\"\"\n",
    "        return STT.create(\n",
    "            provider=\"cartesia\",\n",
    "            model=self.config.stt_model,\n",
    "            api_key=self.config.cartesia_api_key\n",
    "        )\n",
    "    \n",
    "    def _setup_tts(self) -> TTS:\n",
    "        \"\"\"Configure Cartesia Text-to-Speech\"\"\"\n",
    "        return TTS.create(\n",
    "            provider=\"cartesia\",\n",
    "            model=self.config.tts_model,\n",
    "            api_key=self.config.cartesia_api_key,\n",
    "            voice_id=\"friendly-sales\"  # Pre-configured sales voice\n",
    "        )\n",
    "    \n",
    "    def _setup_vad(self) -> VoiceActivityDetector:\n",
    "        \"\"\"Configure Voice Activity Detection\"\"\"\n",
    "        return VoiceActivityDetector.create(provider=\"cilero\")\n",
    "    \n",
    "    def _create_instructions(self) -> str:\n",
    "        \"\"\"Create comprehensive sales agent instructions\"\"\"\n",
    "        base_instructions = f\"\"\"\n",
    "        You are a professional sales agent communicating by voice with potential customers.\n",
    "        \n",
    "        IMPORTANT RULES:\n",
    "        1. Speak naturally and conversationally - no bullet points or lists\n",
    "        2. Be helpful, engaging, and professional\n",
    "        3. Keep responses concise but informative\n",
    "        4. Only use information from the provided context\n",
    "        5. If asked about something not in context, politely say you don't have that information\n",
    "        \n",
    "        CONTEXT INFORMATION:\n",
    "        {self.context.get_context_prompt()}\n",
    "        \n",
    "        SALES GUIDELINES:\n",
    "        - Build rapport with customers\n",
    "        - Understand their needs before pushing products\n",
    "        - Handle objections professionally using the provided responses\n",
    "        - Focus on benefits and value, not just features\n",
    "        - Guide the conversation toward a positive outcome\n",
    "        \n",
    "        CONVERSATION FLOW:\n",
    "        1. Greet warmly and introduce yourself\n",
    "        2. Ask about their needs or challenges\n",
    "        3. Listen actively and ask follow-up questions\n",
    "        4. Present relevant solutions\n",
    "        5. Address concerns professionally\n",
    "        6. Guide toward next steps\n",
    "        \"\"\"\n",
    "        return base_instructions\n",
    "    \n",
    "    async def on_enter(self, ctx: JobContext):\n",
    "        \"\"\"Triggered when someone joins the conversation\"\"\"\n",
    "        greeting = \"\"\"\n",
    "        Hello! Welcome to our sales consultation. I'm your AI sales assistant. \n",
    "        I'm here to help you find the perfect solution for your needs. \n",
    "        What brings you here today, and how can I assist you?\n",
    "        \"\"\"\n",
    "        await ctx.reply(greeting)\n",
    "\n",
    "# Multi-Agent System for Specialized Sales\n",
    "class TechnicalSpecialistAgent(SalesAgent):\n",
    "    def _create_instructions(self) -> str:\n",
    "        base_instructions = super()._create_instructions()\n",
    "        specialized_instructions = \"\"\"\n",
    "        SPECIALIZATION: Technical Expert\n",
    "        - Focus on technical specifications and integration details\n",
    "        - Explain complex concepts in simple terms\n",
    "        - Provide technical comparisons and implementation guidance\n",
    "        - Address technical concerns and compatibility issues\n",
    "        \"\"\"\n",
    "        return base_instructions + specialized_instructions\n",
    "\n",
    "class PricingSpecialistAgent(SalesAgent):\n",
    "    def _create_instructions(self) -> str:\n",
    "        base_instructions = super()._create_instructions()\n",
    "        specialized_instructions = \"\"\"\n",
    "        SPECIALIZATION: Pricing and ROI Expert\n",
    "        - Focus on cost-benefit analysis and ROI calculations\n",
    "        - Explain pricing tiers and value propositions\n",
    "        - Handle budget discussions and payment options\n",
    "        - Provide case studies and success metrics\n",
    "        \"\"\"\n",
    "        return base_instructions + specialized_instructions\n",
    "\n",
    "# Main Application Entry Point\n",
    "class SalesAgentApplication:\n",
    "    def __init__(self, config: AgentConfig):\n",
    "        self.config = config\n",
    "        self.agents = {}\n",
    "        self.setup_agents()\n",
    "    \n",
    "    def setup_agents(self):\n",
    "        \"\"\"Initialize all specialized agents\"\"\"\n",
    "        # Load common sales context\n",
    "        context = SalesContext()\n",
    "        context.load_context(self._load_sales_data())\n",
    "        \n",
    "        # Create specialized agents\n",
    "        self.agents[\"greeting\"] = SalesAgent(config, context)\n",
    "        self.agents[\"technical\"] = TechnicalSpecialistAgent(config, context)\n",
    "        self.agents[\"pricing\"] = PricingSpecialistAgent(config, context)\n",
    "    \n",
    "    def _load_sales_data(self) -> Dict:\n",
    "        \"\"\"Load product and sales data\"\"\"\n",
    "        return {\n",
    "            \"product_description\": {\n",
    "                \"name\": \"AI Sales Platform\",\n",
    "                \"description\": \"Cutting-edge AI platform for automated sales and customer engagement\"\n",
    "            },\n",
    "            \"key_benefits\": [\n",
    "                \"Increase conversion rates by 40%\",\n",
    "                \"Reduce sales cycle time by 60%\",\n",
    "                \"24/7 customer engagement\",\n",
    "                \"Personalized customer interactions\"\n",
    "            ],\n",
    "            \"pricing\": {\n",
    "                \"Starter\": \"$99/month\",\n",
    "                \"Professional\": \"$299/month\", \n",
    "                \"Enterprise\": \"Custom pricing\"\n",
    "            },\n",
    "            \"objection_handlers\": {\n",
    "                \"It's too expensive\": \"I understand cost is important. Let's look at the ROI - most clients see 3x return in the first six months.\",\n",
    "                \"I need to think about it\": \"That's completely understandable. What specific concerns can I address to help with your decision?\",\n",
    "                \"I'm not sure we need this\": \"Many of our clients felt the same initially. Would you like me to share some case studies showing similar companies' results?\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    async def start_agent(self, agent_type: str = \"greeting\"):\n",
    "        \"\"\"Start the specified agent\"\"\"\n",
    "        agent = self.agents.get(agent_type, self.agents[\"greeting\"])\n",
    "        \n",
    "        # Connect to LiveKit room\n",
    "        pipeline = VoicePipeline(agent)\n",
    "        await pipeline.connect()\n",
    "        \n",
    "        return pipeline\n",
    "\n",
    "# Usage Example\n",
    "async def main():\n",
    "    # Configuration\n",
    "    config = AgentConfig(\n",
    "        cerebras_api_key=os.getenv(\"CEREBRAS_API_KEY\"),\n",
    "        livekit_api_key=os.getenv(\"LIVEKIT_API_KEY\"),\n",
    "        cartesia_api_key=os.getenv(\"CARTESIA_API_KEY\")\n",
    "    )\n",
    "    \n",
    "    # Create application\n",
    "    app = SalesAgentApplication(config)\n",
    "    \n",
    "    # Start the sales agent\n",
    "    pipeline = await app.start_agent(\"greeting\")\n",
    "    \n",
    "    print(\"Sales agent is running...\")\n",
    "    # The agent will now handle conversations automatically\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace31aa4-6b75-4dd4-8324-c74021a5fb18",
   "metadata": {},
   "source": [
    "2. Deep Research Agent with Exa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af48995-1e20-426f-bec7-a7f1ab1d9592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soluiton 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bce9962-dc32-4f9f-aed9-3394726475c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "from typing import Dict, List, Optional, Any\n",
    "from dataclasses import dataclass\n",
    "from exa_py import Exa\n",
    "from cerebras.cloud.sdk import Cerebras\n",
    "\n",
    "@dataclass\n",
    "class ResearchConfig:\n",
    "    cerebras_api_key: str\n",
    "    exa_api_key: str\n",
    "    model: str = \"llama-3-70b\"\n",
    "    max_sources: int = 5\n",
    "    content_length: int = 2000\n",
    "\n",
    "class ResearchAgent:\n",
    "    def __init__(self, config: ResearchConfig):\n",
    "        self.config = config\n",
    "        self.exa = Exa(api_key=config.exa_api_key)\n",
    "        self.cerebras = Cerebras(api_key=config.cerebras_api_key)\n",
    "        \n",
    "    async def search_web(self, query: str, num_results: int = 5) -> List[Dict]:\n",
    "        \"\"\"Search the web using Exa API\"\"\"\n",
    "        try:\n",
    "            response = self.exa.search_and_contents(\n",
    "                query,\n",
    "                type=\"auto\",  # Auto-choose between keyword and neural search\n",
    "                text=True,    # Get full content\n",
    "                num_results=num_results\n",
    "            )\n",
    "            \n",
    "            results = []\n",
    "            for result in response.results:\n",
    "                if len(result.text or '') > 200:  # Filter substantial content\n",
    "                    results.append({\n",
    "                        'title': result.title,\n",
    "                        'url': result.url,\n",
    "                        'content': result.text,\n",
    "                        'published_date': result.published_date\n",
    "                    })\n",
    "            \n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"Search error: {e}\")\n",
    "            return []\n",
    "    \n",
    "    async def ask_ai(self, question: str, context: str, temperature: float = 0.2) -> str:\n",
    "        \"\"\"Query Cerebras LLM with context\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        RESEARCH TASK: Analyze the following sources and answer the question.\n",
    "        \n",
    "        QUESTION: {question}\n",
    "        \n",
    "        SOURCES:\n",
    "        {context}\n",
    "        \n",
    "        Please provide:\n",
    "        1. A comprehensive summary of key findings\n",
    "        2. Specific insights and patterns identified\n",
    "        3. Any contradictions or uncertainties found\n",
    "        4. Practical implications or recommendations\n",
    "        \n",
    "        Format your response clearly with sections.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.cerebras.completions.create(\n",
    "                model=self.config.model,\n",
    "                prompt=prompt,\n",
    "                max_tokens=2000,\n",
    "                temperature=temperature,\n",
    "                stop=[\"###\", \"END\"]\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].text.strip()\n",
    "        except Exception as e:\n",
    "            return f\"Error generating response: {e}\"\n",
    "    \n",
    "    async def research_topic(self, topic: str) -> Dict[str, Any]:\n",
    "        \"\"\"Basic research function - single search and analysis\"\"\"\n",
    "        print(f\"Researching: {topic}\")\n",
    "        \n",
    "        # Step 1: Search for sources\n",
    "        sources = await self.search_web(topic, self.config.max_sources)\n",
    "        \n",
    "        if not sources:\n",
    "            return {\"error\": \"No substantial sources found\"}\n",
    "        \n",
    "        # Step 2: Prepare context for LLM\n",
    "        context = self._prepare_context(sources)\n",
    "        \n",
    "        # Step 3: Analyze with LLM\n",
    "        analysis = await self.ask_ai(topic, context)\n",
    "        \n",
    "        return {\n",
    "            \"topic\": topic,\n",
    "            \"sources_used\": len(sources),\n",
    "            \"analysis\": analysis,\n",
    "            \"source_urls\": [s['url'] for s in sources]\n",
    "        }\n",
    "    \n",
    "    async def deep_research_topic(self, topic: str, max_iterations: int = 2) -> Dict[str, Any]:\n",
    "        \"\"\"Advanced research with recursive gap analysis\"\"\"\n",
    "        print(f\"Deep researching: {topic}\")\n",
    "        \n",
    "        all_sources = []\n",
    "        current_question = topic\n",
    "        \n",
    "        for iteration in range(max_iterations):\n",
    "            print(f\"Iteration {iteration + 1}\")\n",
    "            \n",
    "            # Search for current question\n",
    "            new_sources = await self.search_web(current_question, 3)\n",
    "            all_sources.extend(new_sources)\n",
    "            \n",
    "            if not new_sources:\n",
    "                break\n",
    "                \n",
    "            # Analyze current state\n",
    "            context = self._prepare_context(all_sources)\n",
    "            initial_analysis = await self.ask_ai(current_question, context)\n",
    "            \n",
    "            # Identify knowledge gaps\n",
    "            gap_analysis = await self.identify_gaps(topic, initial_analysis, context)\n",
    "            \n",
    "            if not gap_analysis.get('needs_followup', False):\n",
    "                break\n",
    "                \n",
    "            current_question = gap_analysis['followup_question']\n",
    "        \n",
    "        # Final comprehensive analysis\n",
    "        final_context = self._prepare_context(all_sources)\n",
    "        final_analysis = await self.ask_ai(topic, final_context)\n",
    "        \n",
    "        return {\n",
    "            \"topic\": topic,\n",
    "            \"iterations\": iteration + 1,\n",
    "            \"total_sources\": len(all_sources),\n",
    "            \"final_analysis\": final_analysis,\n",
    "            \"source_urls\": [s['url'] for s in all_sources]\n",
    "        }\n",
    "    \n",
    "    async def identify_gaps(self, original_question: str, current_analysis: str, context: str) -> Dict:\n",
    "        \"\"\"Identify gaps in current research and suggest follow-up questions\"\"\"\n",
    "        gap_prompt = f\"\"\"\n",
    "        Based on the current research analysis, identify the most important knowledge gap.\n",
    "        \n",
    "        ORIGINAL QUESTION: {original_question}\n",
    "        \n",
    "        CURRENT ANALYSIS:\n",
    "        {current_analysis}\n",
    "        \n",
    "        SOURCES ANALYZED:\n",
    "        {context}\n",
    "        \n",
    "        Please provide:\n",
    "        1. Assessment of whether follow-up research is needed\n",
    "        2. The most important unanswered question\n",
    "        3. Why this gap is significant\n",
    "        \n",
    "        Respond in JSON format:\n",
    "        {{\n",
    "            \"needs_followup\": true/false,\n",
    "            \"followup_question\": \"specific question to research\",\n",
    "            \"gap_significance\": \"why this gap matters\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.cerebras.completions.create(\n",
    "                model=self.config.model,\n",
    "                prompt=gap_prompt,\n",
    "                max_tokens=500,\n",
    "                temperature=0.1\n",
    "            )\n",
    "            \n",
    "            result_text = response.choices[0].text.strip()\n",
    "            return json.loads(result_text)\n",
    "        except:\n",
    "            return {\"needs_followup\": False, \"followup_question\": \"\", \"gap_significance\": \"\"}\n",
    "    \n",
    "    def _prepare_context(self, sources: List[Dict]) -> str:\n",
    "        \"\"\"Prepare source content for LLM context\"\"\"\n",
    "        context_parts = []\n",
    "        for i, source in enumerate(sources, 1):\n",
    "            context_parts.append(f\"SOURCE {i}: {source['title']}\")\n",
    "            context_parts.append(f\"URL: {source['url']}\")\n",
    "            context_parts.append(f\"CONTENT: {source['content'][:1000]}...\")  # Truncate long content\n",
    "            context_parts.append(\"---\")\n",
    "        \n",
    "        return \"\\n\".join(context_parts)\n",
    "\n",
    "# Multi-Agent Research System (Anthrophic-style)\n",
    "class MultiAgentResearchSystem:\n",
    "    def __init__(self, config: ResearchConfig):\n",
    "        self.config = config\n",
    "        self.agents = {\n",
    "            'lead': ResearchAgent(config),\n",
    "            'technical': ResearchAgent(config),\n",
    "            'market': ResearchAgent(config),\n",
    "            'synthesis': ResearchAgent(config)\n",
    "        }\n",
    "    \n",
    "    async def research_with_agents(self, topic: str) -> Dict:\n",
    "        \"\"\"Conduct research using multiple specialized agents\"\"\"\n",
    "        print(\"Starting multi-agent research...\")\n",
    "        \n",
    "        # Lead agent breaks down the topic\n",
    "        breakdown = await self._breakdown_topic(topic)\n",
    "        \n",
    "        # Run specialized research in parallel\n",
    "        tasks = []\n",
    "        for subtopic in breakdown.get('subtopics', []):\n",
    "            if 'technical' in subtopic.lower():\n",
    "                tasks.append(self.agents['technical'].deep_research_topic(subtopic))\n",
    "            elif 'market' in subtopic.lower() or 'business' in subtopic.lower():\n",
    "                tasks.append(self.agents['market'].deep_research_topic(subtopic))\n",
    "            else:\n",
    "                tasks.append(self.agents['lead'].deep_research_topic(subtopic))\n",
    "        \n",
    "        # Wait for all research to complete\n",
    "        results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "        \n",
    "        # Synthesize final report\n",
    "        synthesis = await self._synthesize_results(topic, results)\n",
    "        \n",
    "        return synthesis\n",
    "    \n",
    "    async def _breakdown_topic(self, topic: str) -> Dict:\n",
    "        \"\"\"Break down complex topic into subtopics\"\"\"\n",
    "        breakdown_prompt = f\"\"\"\n",
    "        Break down this research topic into specialized subtopics for parallel research:\n",
    "        \n",
    "        TOPIC: {topic}\n",
    "        \n",
    "        Provide a JSON response with:\n",
    "        - main_topic: the original topic\n",
    "        - subtopics: list of 3-5 specialized areas to research\n",
    "        - research_focus: brief description of what each subtopic should cover\n",
    "        \"\"\"\n",
    "        \n",
    "        # Implementation similar to ask_ai method\n",
    "        # ... (code for LLM interaction)\n",
    "        return {\"subtopics\": [topic]}  # Simplified\n",
    "    \n",
    "    async def _synthesize_results(self, topic: str, results: List) -> Dict:\n",
    "        \"\"\"Synthesize results from multiple research agents\"\"\"\n",
    "        synthesis_prompt = f\"\"\"\n",
    "        Synthesize research findings from multiple specialized agents:\n",
    "        \n",
    "        ORIGINAL TOPIC: {topic}\n",
    "        \n",
    "        RESEARCH RESULTS: {json.dumps(results, indent=2)}\n",
    "        \n",
    "        Create a comprehensive final report that:\n",
    "        1. Integrates findings from all sources\n",
    "        2. Identifies key patterns and insights\n",
    "        3. Highlights areas of consensus and disagreement\n",
    "        4. Provides actionable recommendations\n",
    "        \"\"\"\n",
    "        \n",
    "        # Implementation similar to ask_ai method\n",
    "        return {\"synthesis\": \"Integrated research report\"}\n",
    "\n",
    "# Usage Example\n",
    "async def research_demo():\n",
    "    config = ResearchConfig(\n",
    "        cerebras_api_key=os.getenv(\"CEREBRAS_API_KEY\"),\n",
    "        exa_api_key=os.getenv(\"EXA_API_KEY\")\n",
    "    )\n",
    "    \n",
    "    agent = ResearchAgent(config)\n",
    "    \n",
    "    # Basic research\n",
    "    result = await agent.research_topic(\"AI in healthcare 2024\")\n",
    "    print(\"Basic Research Result:\")\n",
    "    print(json.dumps(result, indent=2))\n",
    "    \n",
    "    # Deep research\n",
    "    deep_result = await agent.deep_research_topic(\"quantum computing advances 2024\")\n",
    "    print(\"\\nDeep Research Result:\")\n",
    "    print(json.dumps(deep_result, indent=2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(research_demo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68952159-5414-4e44-9241-641f031399fd",
   "metadata": {},
   "source": [
    "3. User Research Agent with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870644c0-9ba9-4dbe-a072-5c93867a42c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dce9b67-c2a8-4b41-8be7-a62a34344743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from typing import Dict, List, Optional, Any\n",
    "from dataclasses import dataclass\n",
    "from langchain.schema import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from pydantic import BaseModel\n",
    "\n",
    "@dataclass\n",
    "class UserResearchConfig:\n",
    "    cerebras_api_key: str\n",
    "    model: str = \"llama-3-70b\"\n",
    "    num_personas: int = 5\n",
    "    questions_per_interview: int = 3\n",
    "\n",
    "# State management using Pydantic models\n",
    "class InterviewState(BaseModel):\n",
    "    research_question: str\n",
    "    personas: List[Dict[str, Any]] = []\n",
    "    interviews: Dict[str, List[Dict]] = {}\n",
    "    current_persona_index: int = 0\n",
    "    current_question_index: int = 0\n",
    "    insights: Dict[str, Any] = {}\n",
    "    follow_up_context: Dict[str, Any] = {}\n",
    "\n",
    "class UserResearchAgent:\n",
    "    def __init__(self, config: UserResearchConfig):\n",
    "        self.config = config\n",
    "        self.llm = self._setup_llm()\n",
    "        self.workflow = self._build_workflow()\n",
    "    \n",
    "    def _setup_llm(self):\n",
    "        \"\"\"Configure Cerebras LLM through LangChain\"\"\"\n",
    "        # Note: This would use a custom Cerebras LangChain integration\n",
    "        # For now, using OpenAI format as placeholder\n",
    "        return ChatOpenAI(\n",
    "            model_name=self.config.model,\n",
    "            openai_api_base=\"https://api.cerebras.ai/v1\",\n",
    "            openai_api_key=self.config.cerebras_api_key\n",
    "        )\n",
    "    \n",
    "    def _build_workflow(self) -> StateGraph:\n",
    "        \"\"\"Build LangGraph workflow for user research\"\"\"\n",
    "        workflow = StateGraph(InterviewState)\n",
    "        \n",
    "        # Add nodes\n",
    "        workflow.add_node(\"configure_research\", self.configure_research)\n",
    "        workflow.add_node(\"generate_personas\", self.generate_personas)\n",
    "        workflow.add_node(\"conduct_interview\", self.conduct_interview)\n",
    "        workflow.add_node(\"synthesize_insights\", self.synthesize_insights)\n",
    "        workflow.add_node(\"generate_followup\", self.generate_followup)\n",
    "        \n",
    "        # Define workflow flow\n",
    "        workflow.set_entry_point(\"configure_research\")\n",
    "        workflow.add_edge(\"configure_research\", \"generate_personas\")\n",
    "        workflow.add_edge(\"generate_personas\", \"conduct_interview\")\n",
    "        \n",
    "        # Conditional edges for interview flow\n",
    "        workflow.add_conditional_edges(\n",
    "            \"conduct_interview\",\n",
    "            self.should_continue_interview,\n",
    "            {\n",
    "                \"next_persona\": \"conduct_interview\",\n",
    "                \"next_question\": \"generate_followup\", \n",
    "                \"synthesize\": \"synthesize_insights\"\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        workflow.add_edge(\"generate_followup\", \"conduct_interview\")\n",
    "        workflow.add_edge(\"synthesize_insights\", END)\n",
    "        \n",
    "        return workflow.compile()\n",
    "    \n",
    "    async def configure_research(self, state: InterviewState) -> InterviewState:\n",
    "        \"\"\"Node 1: Configure research parameters\"\"\"\n",
    "        print(\"Configuring research...\")\n",
    "        \n",
    "        # Generate interview questions based on research topic\n",
    "        questions_prompt = f\"\"\"\n",
    "        Generate {self.config.questions_per_interview} open-ended interview questions \n",
    "        for user research on: {state.research_question}\n",
    "        \n",
    "        Questions should:\n",
    "        - Reveal user motivations and pain points\n",
    "        - Be open-ended to encourage detailed responses\n",
    "        - Cover different aspects of the topic\n",
    "        - Avoid yes/no questions\n",
    "        \n",
    "        Return as JSON list of questions.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = await self.llm.agenerate([questions_prompt])\n",
    "        questions = self._parse_json_response(response)\n",
    "        \n",
    "        state.interviews[\"questions\"] = questions\n",
    "        return state\n",
    "    \n",
    "    async def generate_personas(self, state: InterviewState) -> InterviewState:\n",
    "        \"\"\"Node 2: Generate diverse user personas\"\"\"\n",
    "        print(\"Generating personas...\")\n",
    "        \n",
    "        persona_prompt = f\"\"\"\n",
    "        Generate {self.config.num_personas} diverse user personas for research on: {state.research_question}\n",
    "        \n",
    "        Each persona should include:\n",
    "        - Name and age\n",
    "        - Background and profession\n",
    "        - Technical proficiency level\n",
    "        - Key motivations and pain points\n",
    "        - Communication style\n",
    "        - Specific needs related to the research topic\n",
    "        \n",
    "        Make personas diverse in age, background, and perspectives.\n",
    "        Return as JSON list of personas.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = await self.llm.agenerate([persona_prompt])\n",
    "        state.personas = self._parse_json_response(response)\n",
    "        \n",
    "        # Initialize interview tracking\n",
    "        for persona in state.personas:\n",
    "            state.interviews[persona['name']] = []\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    async def conduct_interview(self, state: InterviewState) -> InterviewState:\n",
    "        \"\"\"Node 3: Conduct AI-powered interview with persona\"\"\"\n",
    "        current_persona = state.personas[state.current_persona_index]\n",
    "        current_question = state.interviews[\"questions\"][state.current_question_index]\n",
    "        \n",
    "        print(f\"Interviewing {current_persona['name']}...\")\n",
    "        \n",
    "        # Prepare interview context\n",
    "        interview_prompt = self._create_interview_prompt(\n",
    "            current_persona, \n",
    "            current_question,\n",
    "            state\n",
    "        )\n",
    "        \n",
    "        # Get persona response\n",
    "        response = await self.llm.agenerate([interview_prompt])\n",
    "        persona_response = response.generations[0][0].text\n",
    "        \n",
    "        # Store interview data\n",
    "        interview_data = {\n",
    "            \"question\": current_question,\n",
    "            \"response\": persona_response,\n",
    "            \"question_index\": state.current_question_index,\n",
    "            \"follow_up_context\": state.follow_up_context.get(current_persona['name'], {})\n",
    "        }\n",
    "        \n",
    "        state.interviews[current_persona['name']].append(interview_data)\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    async def generate_followup(self, state: InterviewState) -> InterviewState:\n",
    "        \"\"\"Node 4: Generate contextual follow-up questions\"\"\"\n",
    "        current_persona = state.personas[state.current_persona_index]\n",
    "        recent_responses = state.interviews[current_persona['name']][-2:]  # Last 2 responses\n",
    "        \n",
    "        if len(recent_responses) < 2:\n",
    "            # Move to next question if not enough context for follow-up\n",
    "            state.current_question_index += 1\n",
    "            return state\n",
    "        \n",
    "        followup_prompt = f\"\"\"\n",
    "        Based on the persona's recent responses, generate a natural follow-up question.\n",
    "        \n",
    "        PERSONA: {current_persona}\n",
    "        \n",
    "        RECENT RESPONSES: {recent_responses}\n",
    "        \n",
    "        Create a follow-up question that:\n",
    "        - Digs deeper into interesting points\n",
    "        - Explores motivations behind statements\n",
    "        - Maintains natural conversation flow\n",
    "        - Is open-ended and exploratory\n",
    "        \n",
    "        Return only the follow-up question.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = await self.llm.agenerate([followup_prompt])\n",
    "        followup_question = response.generations[0][0].text.strip()\n",
    "        \n",
    "        # Add follow-up to questions list\n",
    "        state.interviews[\"questions\"].append(followup_question)\n",
    "        state.current_question_index = len(state.interviews[\"questions\"]) - 1\n",
    "        \n",
    "        # Update follow-up context\n",
    "        persona_name = current_persona['name']\n",
    "        if persona_name not in state.follow_up_context:\n",
    "            state.follow_up_context[persona_name] = {}\n",
    "        state.follow_up_context[persona_name][\"last_followup\"] = followup_question\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    async def synthesize_insights(self, state: InterviewState) -> InterviewState:\n",
    "        \"\"\"Node 5: Synthesize insights from all interviews\"\"\"\n",
    "        print(\"Synthesizing insights...\")\n",
    "        \n",
    "        synthesis_prompt = self._create_synthesis_prompt(state)\n",
    "        response = await self.llm.agenerate([synthesis_prompt])\n",
    "        \n",
    "        insights = self._parse_json_response(response)\n",
    "        state.insights = insights\n",
    "        \n",
    "        print(\"Research complete! Insights generated.\")\n",
    "        return state\n",
    "    \n",
    "    def should_continue_interview(self, state: InterviewState) -> str:\n",
    "        \"\"\"Determine next step in interview flow\"\"\"\n",
    "        # Check if all personas have been interviewed\n",
    "        if state.current_persona_index < len(state.personas) - 1:\n",
    "            state.current_persona_index += 1\n",
    "            state.current_question_index = 0\n",
    "            return \"next_persona\"\n",
    "        \n",
    "        # Check if all questions have been asked\n",
    "        if state.current_question_index < len(state.interviews[\"questions\"]) - 1:\n",
    "            state.current_question_index += 1\n",
    "            state.current_persona_index = 0  # Start with first persona for next question\n",
    "            return \"next_question\"\n",
    "        \n",
    "        # All interviews complete\n",
    "        return \"synthesize\"\n",
    "    \n",
    "    def _create_interview_prompt(self, persona: Dict, question: str, state: InterviewState) -> str:\n",
    "        \"\"\"Create prompt for persona response generation\"\"\"\n",
    "        return f\"\"\"\n",
    "        You are role-playing as: {persona}\n",
    "        \n",
    "        Research Context: {state.research_question}\n",
    "        \n",
    "        Interview Question: {question}\n",
    "        \n",
    "        Respond naturally as this persona would:\n",
    "        - Stay true to the persona's background and characteristics\n",
    "        - Provide detailed, thoughtful responses\n",
    "        - Express personal opinions and experiences\n",
    "        - Be authentic and believable\n",
    "        \n",
    "        Previous responses in this interview: {state.interviews.get(persona['name'], [])}\n",
    "        \n",
    "        Response:\n",
    "        \"\"\"\n",
    "    \n",
    "    def _create_synthesis_prompt(self, state: InterviewState) -> str:\n",
    "        \"\"\"Create prompt for insight synthesis\"\"\"\n",
    "        all_interviews = []\n",
    "        for persona_name, interviews in state.interviews.items():\n",
    "            if persona_name != \"questions\":  # Skip questions key\n",
    "                all_interviews.append({\n",
    "                    \"persona\": persona_name,\n",
    "                    \"responses\": interviews\n",
    "                })\n",
    "        \n",
    "        return f\"\"\"\n",
    "        Analyze the following user research interviews and synthesize key insights.\n",
    "        \n",
    "        RESEARCH TOPIC: {state.research_question}\n",
    "        \n",
    "        INTERVIEW DATA: {all_interviews}\n",
    "        \n",
    "        Provide a comprehensive analysis including:\n",
    "        1. Key patterns and themes across personas\n",
    "        2. Surprising or unexpected findings\n",
    "        3. User pain points and frustrations\n",
    "        4. Opportunities and recommendations\n",
    "        5. Demographic variations in responses\n",
    "        \n",
    "        Format as JSON with clear sections.\n",
    "        \"\"\"\n",
    "    \n",
    "    def _parse_json_response(self, response) -> Any:\n",
    "        \"\"\"Parse JSON response from LLM\"\"\"\n",
    "        # Implementation for extracting JSON from LLM response\n",
    "        try:\n",
    "            import json\n",
    "            text = response.generations[0][0].text\n",
    "            # Extract JSON from text if needed\n",
    "            start = text.find('{')\n",
    "            end = text.rfind('}') + 1\n",
    "            if start != -1 and end != 0:\n",
    "                return json.loads(text[start:end])\n",
    "        except:\n",
    "            pass\n",
    "        return []\n",
    "\n",
    "# Enhanced Research System with Multi-Question Interviews\n",
    "class EnhancedUserResearchAgent(UserResearchAgent):\n",
    "    def __init__(self, config: UserResearchConfig):\n",
    "        super().__init__(config)\n",
    "        # Additional enhancements for multi-question flow\n",
    "    \n",
    "    async def conduct_interview(self, state: InterviewState) -> InterviewState:\n",
    "        \"\"\"Enhanced interview with conversation memory\"\"\"\n",
    "        # Implementation with conversation memory and context tracking\n",
    "        return await super().conduct_interview(state)\n",
    "\n",
    "# Usage Example\n",
    "async def user_research_demo():\n",
    "    config = UserResearchConfig(\n",
    "        cerebras_api_key=os.getenv(\"CEREBRAS_API_KEY\"),\n",
    "        num_personas=3,\n",
    "        questions_per_interview=2\n",
    "    )\n",
    "    \n",
    "    agent = UserResearchAgent(config)\n",
    "    \n",
    "    # Initialize research state\n",
    "    initial_state = InterviewState(\n",
    "        research_question=\"How can we improve mobile banking apps for young professionals?\"\n",
    "    )\n",
    "    \n",
    "    # Run the research workflow\n",
    "    final_state = await agent.workflow.ainvoke(initial_state)\n",
    "    \n",
    "    print(\"Research Insights:\")\n",
    "    print(final_state.insights)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(user_research_demo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f8b602-c625-4b96-8b81-1c47651d3de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
